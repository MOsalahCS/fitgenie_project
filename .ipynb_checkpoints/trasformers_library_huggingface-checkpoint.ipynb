{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81594c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "     ------------------------------------ 131.1/131.1 kB 966.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohamed__salh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "   ---------------------------------------- 8.5/8.5 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "   ---------------------------------------- 330.1/330.1 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.2-cp39-none-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 269.7/269.7 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ---------------------------------------- 170.9/170.9 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.2.0\n",
      "    Uninstalling fsspec-2022.2.0:\n",
      "      Successfully uninstalled fsspec-2022.2.0\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.20.3 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161e788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ed5c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c901f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\",model=model, tokenizer=tokenizer)\n",
    "\n",
    "res = classifier([\"We are very happy to show the hugging face transformers library .\",\n",
    "                  \n",
    "                  \"We hope you don't like it \"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2f6e72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'POSITIVE', 'score': 0.9997256398200989}\n",
      "{'label': 'NEGATIVE', 'score': 0.898459792137146}\n"
     ]
    }
   ],
   "source": [
    "for results in res:\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bda3658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokens :['we', 'are', 'very', 'happy', 'to', 'show', 'the', 'hugging', 'face', 'transformers', 'library', '.']\n",
      " Token IDs :[2057, 2024, 2200, 3407, 2000, 2265, 1996, 17662, 2227, 19081, 3075, 1012]\n",
      " input ID :{'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2265, 1996, 17662, 2227, 19081, 3075, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"We are very happy to show the hugging face transformers library .\")\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "token_id = tokenizer(\"We are very happy to show the hugging face transformers library \")\n",
    "\n",
    "print(f' Tokens :{tokens}')\n",
    "print(f' Token IDs :{tokens_ids}')\n",
    "print(f' input ID :{token_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bf68347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2057,  2024,  2200,  3407,  2000,  2265,  1996, 17662,  2227,\n",
       "         19081,  3075,  1012,   102],\n",
       "        [  101,  2057,  3246,  2017,  2123,  1005,  1056,  2066,  2009,   102,\n",
       "             0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [\"We are very happy to show the hugging face transformers library .\",\n",
    "                  \n",
    "                  \"We hope you don't like it \"]\n",
    "\n",
    "batch = tokenizer(X_train,padding=True, truncation=True, max_length=512 , return_tensors=\"pt\")\n",
    "\n",
    "batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a86a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.9936,  4.2071],\n",
      "        [ 1.1751, -1.0051]]), hidden_states=None, attentions=None)\n",
      "tensor([[2.7439e-04, 9.9973e-01],\n",
      "        [8.9846e-01, 1.0154e-01]])\n",
      "tensor([1, 0])\n",
      "['POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits , dim=1)\n",
    "    print(predictions)\n",
    "    labels = torch.argmax(predictions , dim= 1)\n",
    "    print(labels)\n",
    "    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652188b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
